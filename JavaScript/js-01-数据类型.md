## Undefined

在js中，undefined 是一个变量，在块级作用域中，它能被重新赋值(必须先使用 undefined 声明一个函数)，因此我们得知undefined 是一个变量。这是一个Js设计上的缺陷，为了避免 undefined 被篡改，所以很多规范中，都是使用 void 操作符来给变量或常量赋值 undefined 的；

## Null

与 undefined 一样，也是代表空的意思，但区别是， undefined 表示未被赋值，不占用内存，而null表示，赋值了，但是是一个空值，更准确的说，是个未创建的对象。

```js
typeof null //"object"
```

## Boolean

仅表示真假两个值，true 和 false;


## String

现行的字符集国际标准，字符是以 Unicode 的方式表示的，而JS使用的是 UTF16 编码方式（前身是UCS-2）；

String 有最大长度是 2^53 - 1，这在一般开发中都是够用的，但是有趣的是，这个所谓最大长度，是根据字符的 UTF16 编码计算的。charAt、charCodeAt、length 等方法针对的都是 UTF16 编码。

**Js 采用的字符集Unicode及其编码类型：**

因计算机所有的数据在存储和运算时都要使用二进制数表示，那么像26个英文字母、数字等字符也需要使用二进制表示，于是每个符号指定一个编号，这叫做"码点"（code point），于是就有了最初的ASCII编码，但是它只包含了因为字母、阿拉伯数字、及常用英文标点符号。

再后来各种不同语言的编码也出现了，问题也随之而来了，试想下，你在阅读一篇英文文章时编辑器是 ASCII 编码格式，如果在文章底部有部分中文文字，那么 ASCII 就无法识别，就会显示成乱码。

Unicode 源于一个很简单的想法：将全世界所有的字符包含在一个集合里，计算机只要支持这一个字符集，就能显示所有的字符，再也不会有乱码了。

Unicode 的码点通常用 U+??? 来表示，其中 ??? 是十六进制的码点值。 0-65536（U+0000 - U+FFFF）的码点被称为基本字符区域（BMP）。
之所以定这个范围，因为Js使用的编码方法UCS-2（后被整合进UTF-16）决定的，当时 UCS-2 只有一个基本字符区域，每个字符使用两个字节存储。
0xFFFF的二进制就是16个1组成，所以 BMP 范围是 U+0000 - U+FFFF。超出这个范围就属于辅助字符区域，统一使用4个字节存储，这也是 UTF-16 才开始支持的。

BPM 范围内的码点，和字符长度（`String.length`算出）一致，一个码点一个字符长度。超过了这个范围的则一个字符长度为 2。


```js
// BMP范围字符
var word1 = '字';

word1.charCodeAt().toString(16); // "5b57"

word1.length // 1


/*
    以下非BMP字符正确 unicode 应该是 1d306，但是由于 es5 时 js 还不支持非 BMP 的字符，
    所以无法识别 1d306，必须将其拆分成两个码点。
*/

var word2 = '𝌆';

word2 === '\u1d306' // false

word2.charCodeAt(0).toString(16); // "d834"

word2.charCodeAt(1).toString(16); // "df06"

word2 === '\ud834\udf06' // true

word2.length // 2

```

es6 后，大幅增强了Unicode支持，基本上解决了这个问题:

```js

// for of 方法天然识别非 BMP 字符
for (let s of word2) {
  console.log(s); // "𝌆"
}

// length 方法为了兼容历史版本，没有改变
word2.length // 2

// 但是可以用 Array.from 获取准确的长度
Array.from(word2).length // 1

// 同时，非BMP也支持码点表示法，只要加上 '{}' 
word2 === '\u{1d306}' // true

```

同样出于兼容问题的考虑，在不修改 `String.prototype.charCodeAt`、`String.fromCharCode`同时，新增了：

```js
String.fromCodePoint() //从Unicode码点返回对应字符
String.prototype.codePointAt() //从字符返回对应的码点
String.prototype.at() //返回字符串给定位置的字符
```

正则也进行了相应的支持，提供了u修饰符，对正则表达式添加4字节码点的支持。：

```js

/^.$/.test('𝌆'); //false

/^.$/u.test('𝌆'); //true

```

另外还有 Unicode 正规化，涉及到音标的标准化问题，es6添加了 `String.prototype.normalize` 方法来解决，这里不再赘述。


**js: 字符串和Unicode互转：**

```js
// 字符串
var str = "中文";

// 根据下标的字符对应的十进制 Unicode "码点"（code point）
var code = str.charCodeAt(0);

// 根据码点转换成字符串
var str0 = String.fromCharCode(code);

// 转为16进制数
var code16 = code.toString(16);

```

## Number

Number 类型表示我们通常意义上的“数字”。这个数字大致对应数学中的有理数，当然，在计算机中，我们有一定的精度限制。

JavaScript 中的 Number 类型有 18437736874454810627(即 2^64-2^53+3) 个值。

JavaScript 中的 Number 类型基本符合 [IEEE 754-2008](./IEEE754.md) 规定的双精度浮点数规则，但是 JavaScript 为了表达几个额外的语言场景（比如不让除以 0 出错，而引入了无穷大的概念），规定了几个例外情况：
* NaN，占用了 9007199254740990，这原本是符合 IEEE 规则的数字；
* Infinity，无穷大；
* -Infinity，负无穷大。

JavaScript 中，+0和-0大多情况没有区别，但是除法时，比如 1/x 根据x的正负分别得到 Infinity 和 -Infinity。

根据双精度浮点数的定义，Number 类型中有效的整数范围是 -0x1fffffffffffff 至 0x1fffffffffffff（有效数字位52bit，所以最大52+1个bit），所以 Number 无法精确表示此范围外的整数。

来看一段著名代码：

```js
console.log(0.1 + 0.2); //0.30000000000000004
```

因为计算机底层计数都是使用二进制，这里问题的根源是十进制小数转为二进制小数的过程中，会损失精度:

```js
Number(0.1).toString(2); //"0.000110011001100...
Number(0.2).toString(2); //"0.00110011001100...
```
为什么会这样？我们以0.1为例，看下十进制转二进制的过程：

```js
0.1 * 2 = 0.2  -- 0
0.2 * 2 = 0.4  -- 0
0.4 * 2 = 0.8  -- 0
0.8 * 2 = 1.6  -- 1
0.6 * 2 = 1.2  -- 1
0.2 * 2 = 0.4  -- 0
0.4 * 2 = 0.8  -- 0
0.8 * 2 = 1.6  -- 1
0.6 * 2 = 1.2  -- 1
...
```
上面的规律是将数字乘以2，取出整数部分作为二进制表示的第1位；然后再将小数部分乘以2，将得到的整数部分作为二进制表示的第2位；以此类推，直到小数部分为0。 
那么仔细观察，上面示例代码从第二步开始，已经出现循环了，所以这里根本无法停止，直到填满IEEE双精度的有效数字部分(52bit)，这里就产生了舍入误差。
二进制能「用有限的位数」表示的仅有：0.5、0.25、0.125 等。

到这里就很好理解了，拿着存在精度误差的二进制数字，将其转回十进制，当然无法获得准确十进制数字啊。

拿0.1的二进制表示举例：0001 1001 1001 1001 ...
公式 v[i] * 2^( - i ), i 为 index，v[i] 为该位的二进制值
```js
(0 * 2^-1) + (0 * 2^-2) + (0 * 2^-3) + (1 * 2^-4) + ……
```

0.1 + 0.1 为什么等于0.2?

以下是我从网络搜到的材料，讲的比较浅，目前暂时没有更多材料进行进一步了解；
```
两个有舍入误差的值在求和时，相互抵消了，但这种“负负得正，相互抵消”不一定是可靠的，当这两个数字是用不同长度数位来表示的浮点数时，舍入误差可能不会相互抵消。
又如，对于 0.1 + 0.3 ，结果其实并不是0.4，但0.4是最接近真实结果的数，比其它任何浮点数都更接近。许多语言也就直接显示结果为0.4了，而不展示一个浮点数的真实结果了。
```

在Javascript中，精度误差的正确的比较方法是使用 Number.EPSILON：

```js
console.log( Math.abs(0.1 + 0.2 - 0.3) <= Number.EPSILON);
```

Number.EPSILON 是 Javascript 中的最小误差值，等于小于这个值的误差可以忽略了。

## Symbol

Symbol 是ES6中新增的数据类型，它是一切非字符串的对象 key 的集合，在 ES6 规范中，整个对象系统被用 Symbol 重塑。

Symbol 可以具有字符串类型的描述，但是即使描述相同，Symbol 也不相等。

创建：
```js
var mySymbol = Symbol("my symbol");
```

一些标准中提到的 Symbol，可以在全局的 Symbol 函数的属性中找到。例如，我们可以使用 Symbol.iterator 来自定义 for…of 在对象上的行为：

```js
var o = new Object

o[Symbol.iterator] = function() {
    var v = 0
    return {
        next: function() {
            return { value: v++, done: v > 10 }
        }
    }        
};

for(var v of o) 
    console.log(v); // 0 1 2 3 ... 9
```

这些标准中被称为“众所周知”的 Symbol，也构成了语言的一类接口形式。它们允许编写与语言结合更紧密的 API。

## Object

Object 是 JavaScript 中最复杂的类型，也是 JavaScript 的核心机制之一。Object 表示对象的意思，它是一切有形和无形物体的总称。

在 JavaScript 中，对象的定义是“属性的集合”。属性分为数据属性和访问器属性，二者都是 key-value 结构，key 可以是字符串或者 Symbol 类型。

可以根据以下方法查看属性特性，看下属于哪种属性：
```js
Object.getOwnPropertyDescriptor(object,'property');
```
通过value访问的，我们称之为数据属性，而通过get和set操作属性的，我们称之为访问器属性。（可以通过Object.defineProperty设置，两者不能同时设置）
```js
{
    value: "data",
    writable: true,
    enumerable: true,
    configurable: true,
    get fn() {return this.value},
    set fn(value) {this.value = value}
}
```

Javascript 中7种数据类型，只有Object是真正属于引用类型。其他几种都是基本类型。

而这几个基本类型中，有几个在Object中都存在子对象，分别是：

* Number；
* String；
* Boolean；
* Symbol。

所以，我们必须认识到 3 与 new Number(3) 是完全不同的值，它们一个是 Number 类型， 一个是对象类型。

Number、String 和 Boolean，三个构造器是两用的，当跟 new 搭配时，它们产生对象，当直接调用时，它们表示强制类型转换。
Symbol 函数比较特殊，直接用 new 调用它会抛出错误，但它仍然是 Symbol 对象的构造器。

当我们通过.运算符访问以上几种基本类型时，Javascript 会进行一次装箱操作（隐式转换），将基本类型转换为对象，以继承基本类型构造器中的方法；过程如下：

```js
// 声明一个字符串
var str = 'string';
// 通过 .运算符访问时，JavaScript 会进行一次装箱操作
// 也就相当于执行了 new String(str)，于是可以调用一系列方法
str.length;
// 调用完成后，重新拆箱回 string 类型
```

## 类型转换

**StringToNumber**
字符串到数字的类型转换，存在一个语法结构，类型转换支持十进制、二进制、八进制和十六进制，比如：
* 30；
* 0b111；
* 0o13；
* 0xFF。

此外，JavaScript 支持的字符串语法还包括正负号科学计数法，可以使用大写或者小写的 e 来表示：
* 1e3；
* -1e-2。

需要注意的是，parseInt 和 parseFloat 并不使用这个转换，所以支持的语法跟这里不尽相同。在不传入第二个参数的情况下，parseInt 只支持 16 进制前缀“0x”，而且会忽略非数字字符，也不支持科学计数法。在一些古老的浏览器环境中，parseInt 还支持 0 开头的数字作为 8 进制前缀，这是很多错误的来源。所以在任何环境下，都建议传入 parseInt 的第二个参数，而 parseFloat 则直接把原字符串作为十进制来解析，它不会引入任何的其他进制。多数情况下，Number 是比 parseInt 和 parseFloat 更好的选择。

**NumberToString**

在较小的范围内，数字到字符串的转换是完全符合你直觉的十进制表示。当 Number 绝对值较大或者较小时，字符串表示则是使用科学计数法表示的。这个算法细节繁多，我们从感性的角度认识，它其实就是保证了产生的字符串不会过长。

数字转字符串还可以转成不同进制：

```js
//转为二进制
Number(10).toString(2); // 1010
```

**装箱转换**

每一种基本类型 Number、String、Boolean、Symbol 在对象中都有对应的类，所谓装箱转换，正是把基本类型转换为对应的对象，它是类型转换中一种相当重要的种类。

全局的 Symbol 函数无法使用 new 来调用，但我们仍可以利用装箱机制来得到一个 Symbol 对象，我们可以利用一个函数的 call 方法来强迫产生装箱。

```js
var symbolObject =
    (function(){ return this; }).call(Symbol("a"));

console.log(typeof symbolObject); //object
console.log(symbolObject instanceof Symbol); //true
console.log(symbolObject.constructor == Symbol); //true
```
装箱机制会频繁产生临时对象，在一些对性能要求较高的场景下，我们应该尽量避免对基本类型做装箱转换。

使用内置的 Object 函数，我们可以在 JavaScript 代码中显式调用装箱能力。

```js
var symbolObject = Object(Symbol("a"));

console.log(typeof symbolObject); //object
console.log(symbolObject instanceof Symbol); //true
console.log(symbolObject.constructor == Symbol); //true
```

每一类装箱对象皆有私有的 Class 属性，这些属性可以用 Object.prototype.toString 获取：

```js
// Symbol...
console.log(Object.prototype.toString.call(Symbol('a'))); //[object Symbol]
// Array
console.log(Object.prototype.toString.call([])); //[object Array]
console.log(Object.prototype.toString.call(Array())); //[object Array]
console.log(Object.prototype.toString.call(new Array())); //[object Array]
// String
console.log(Object.prototype.toString.call(new String())); //[object String]
console.log(Object.prototype.toString.call(String())); //[object String]
console.log(Object.prototype.toString.call('')); //[object String]
// Object...
console.log(Object.prototype.toString.call(new Object())); //[object Object]
...
```

在 JavaScript 中，没有任何方法可以更改私有的 Class 属性，因此 Object.prototype.toString 是可以准确识别对象对应的基本类型的方法，它比 instanceof 更加准确。

但需要注意的是，call 本身会产生装箱操作，所以需要配合 typeof 来区分基本类型还是对象类型。

**拆箱转换**

在 JavaScript 标准中，规定了 ToPrimitive 函数，它是对象类型到基本类型的转换（即，拆箱转换）。

对象到 String 和 Number 的转换都遵循“先拆箱再转换”的规则。通过拆箱转换，把对象变成基本类型，再从基本类型转换为对应的 String 或者 Number。拆箱转换会尝试调用 valueOf 和 toString 来获得拆箱后的基本类型。如果 valueOf 和 toString 都不存在，或者没有返回基本类型，则会产生类型错误 TypeError。

```js
var o = {
    valueOf : () => {console.log("valueOf"); return {}},
    toString : () => {console.log("toString"); return {}}
}

o * 2
// valueOf
// toString
// TypeError
```

我们定义了一个对象 o，o 有 valueOf 和 toString 两个方法，这两个方法都返回一个对象，然后我们进行 o*2 这个运算的时候，你会看见先执行了 valueOf，接下来是 toString，最后抛出了一个 TypeError，这就说明了这个拆箱转换失败了。

到 String 的拆箱转换会优先调用 toString。我们把刚才的运算从 o*2 换成 String(o)，那么你会看到调用顺序就变了。

```js

var o = {
    valueOf : () => {console.log("valueOf"); return {}},
    toString : () => {console.log("toString"); return {}}
}

String(o)
// toString
// valueOf
// TypeError
```

在 ES6 之后，还允许对象通过显式指定 @@toPrimitive Symbol 来覆盖原有的行为。

```js

    var o = {
        valueOf : () => {console.log("valueOf"); return {}},
        toString : () => {console.log("toString"); return {}}
    }

    o[Symbol.toPrimitive] = () => {console.log("toPrimitive"); return "hello"}


    console.log(o + "")
    // toPrimitive
    // hello
```

关于 valueOf 和 toString 调用顺序：

ecmascript 规范指出，类型转换的内部实现是通过ToPrimitive ( input [ , PreferredType ] )方法进行转换的，这个方法的作用就是将input转换成一个非对象类型。

参数preferredType是可选的，它的作用是，指出了input被期待转成的类型。

如果不传preferredType进来，默认的是'number'。

如果preferredType的值是"string"，那就先执行"toString", 后执行"valueOf"。否则，先执行"valueOf", 后执行"toString"。

由此可见，"toString", "valueOf"的执行顺序，取决于preferred的值。


## 规范类型：

除了这七种语言类型，还有一些语言的实现者更关心的规范类型。

- List 和 Record： 用于描述函数传参过程。
- Set：主要用于解释字符集等。
- Completion Record：用于描述异常、跳出等语句执行过程。
- Reference：用于描述对象属性访问、delete 等。
- Property Descriptor：用于描述对象的属性。
- Lexical Environment 和 Environment Record：用于描述变量和作用域。
- Data Block：用于描述二进制数据。

有一个说法是：程序 = 算法 + 数据结构，运行时类型包含了所有 JavaScript 执行时所需要的数据结构的定义，所以我们要对它格外重视。